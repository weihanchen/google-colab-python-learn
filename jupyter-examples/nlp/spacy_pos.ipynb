{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7J4hBcwnfbmNkujR9Z9ul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weihanchen/google-colab-python-learn/blob/main/jupyter-examples/nlp/spacy_pos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 【自然語言處理 - 概念篇】 詞性標注POS在NLP的世界扮演什麼樣的角色呢?\n",
        "\n",
        "Part-of-Speech Tagging, POS是詞性標注的全名, 主要為詞彙標上語言中的語法類別或用途, 再進行後續的分析與處理, 就想像成文件歸檔的動作, 每個文件貼上一個標籤類別, 而透過這些標籤類別進行關聯性的分類歸檔。\n",
        "\n",
        "一個句子最基本的組成單位是「詞」這在我們之前幾個篇章都有談過，如果還不熟悉的朋友可以複習一下：\n",
        "- [【自然語言處理 — 概念篇】最基礎的Bag-of-Words模型是什麼呢?](https://vocus.cc/article/646b60adfd89780001aae7f4)\n",
        "- [【自然語言處理 - 概念篇】 來認識一下詞向量(Word Embedding or Word Vector)吧](https://www.potatomedia.co/s/bsKx5GfV)\n",
        "- [【自然語言處理 - 概念篇】 探索TF-IDF, 關於詞的統計與索引隱含著什麼奧秘呢？]()\n",
        "\n",
        "但上述的基礎知識都是將「詞」進行量化處理， 以統計的方式估算出相鄰的詞彙, 進行組合, 但這樣缺少了我們人類語言學的一些特徵, 因此才需要針對「詞」加入一些我們語言學的元素, 像是「詞性」就是一個例子, 「看」是一個動詞, 那什麼詞性可以去修飾動詞或者相互依賴就是我們下一個篇章「[【自然語言處理 - spaCy】 拆解語句組成的規則, 何謂依存句法分析(Dependency Parsing)?]()」在介紹的部分, 而這邊主要在說明中文詞性標注POS的部分。\n",
        "\n",
        "## 詞性標注(Part-of-Speech Tagging, POS) 提供了什麼價值?\n",
        "\n",
        "- 語法分析：詞性標注是進行語法分析的重要步驟之一。通過將詞彙標註為相應的詞性，可以幫助理解句子的結構和句法關係，比如主語、動詞、賓語等，從而更好地理解句子的語法。\n",
        "\n",
        "- 語義理解：詞性標注有助於理解詞彙的語義。不同的詞性標籤可以指示詞彙在句子中的角色和含義。通過詞性標注，可以更準確地捕捉詞彙的語義信息，進而進行更精確的文本理解和意義提取。\n",
        "\n",
        "- 上下文分析：詞性標注可以幫助理解詞彙在特定上下文中的含義和用法。同一個詞彙在不同的句子或上下文中可能有不同的詞性，詞性標注可以幫助區分這種差異，從而提供更準確的上下文理解。\n",
        "\n",
        "- 詞彙處理：詞性標注有助於進行詞彙級別的處理和分析。不同詞性的詞彙在語法結構、語義和用法上可能有所不同，詞性標注可以幫助對詞彙進行分類、聚類和相關性分析，從而進行更深入的詞彙處理。\n",
        "\n",
        "- 文本分類和信息檢索：詞性標注可以作為文本分類和信息檢索的特徵之一。將詞彙的詞性作為特徵，可以幫助構建更準確的文本分類模型或搜索引擎，從而提升分類和檢索的效果。\n",
        "\n",
        "總的來說, 中文詞性標注為中文文本分析提供了重要的基礎信息, 可以幫助我們更好地理解語法結構、詞彙語義和上下文含義, 從而支持多種NLP任務, 包括語法分析、語義理解、文本分類。"
      ],
      "metadata": {
        "id": "b9HgCVoI72X2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 看完基本觀念後, 我們用[spaCy](https://spacy.io/)來玩玩看唄\n",
        "\n",
        "[spaCy](https://spacy.io/)是一套處理NLP的框架, 讓我們除了學習以外, 還可以進行一些NLP基礎的任務, 除此之外也提供了基礎任務模型的微調甚至再訓練的方式, 提高目標精準度。\n",
        "\n",
        "### 安裝套件並載入模型"
      ],
      "metadata": {
        "id": "hGTzAqDG-DFz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgB5PUc27zt3"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "\n",
        "# 下載Transfromer技術的中文語言模型\n",
        "!python -m spacy download zh_core_web_trf\n",
        "\n",
        "import spacy\n",
        "\n",
        "# 載入模型\n",
        "nlp_zh = spacy.load('zh_core_web_trf')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 實際來標注一下吧\n",
        "\n",
        "POS有哪些標籤呢? 請參考「[https://universaldependencies.org/u/pos/](https://universaldependencies.org/u/pos/)」\n",
        "\n"
      ],
      "metadata": {
        "id": "dDWCAD_C_7qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "sentence = '我昨天看了一本有趣的書。'\n",
        "\n",
        "doc = nlp_zh(sentence)\n",
        "\n",
        "# 建立空的資料框架\n",
        "data = {\"詞語\": [], \"詞性\": []}\n",
        "\n",
        "# 建立詞性與顏色的對應字典\n",
        "pos_colors = {}\n",
        "\n",
        "for token in doc:\n",
        "    # 詞性標籤\n",
        "    pos_tag = token.pos_\n",
        "    \n",
        "    # 將詞語和詞性加入資料框架\n",
        "    data[\"詞語\"].append(token.text)\n",
        "    data[\"詞性\"].append(pos_tag)\n",
        "\n",
        "    # 如果詞性標籤尚未有對應的顏色，則賦予一個隨機顏色\n",
        "    if pos_tag not in pos_colors:\n",
        "        color = \"#%06x\" % random.randint(0, 0xFFFFFF)\n",
        "        pos_colors[pos_tag] = color\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 定義自訂函式來設定詞性欄位的顏色\n",
        "def set_pos_color(pos):\n",
        "    color = pos_colors.get(pos, \"#000000\")  # 若詞性未在字典中，則預設為黑色\n",
        "    return f\"background-color: {color}\"\n",
        "\n",
        "styles = df.style.applymap(lambda x: set_pos_color(x), subset=[\"詞性\"])\n",
        "\n",
        "html = styles.to_html(index=False)\n",
        "\n",
        "display(HTML(html))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "-dY-5-lsG-yM",
        "outputId": "ceb3c3d1-1ae7-41f7-fd26-2815509d4d36"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_01c79_row0_col1 {\n",
              "  background-color: #30b20f;\n",
              "}\n",
              "#T_01c79_row1_col1, #T_01c79_row8_col1 {\n",
              "  background-color: #93cc2b;\n",
              "}\n",
              "#T_01c79_row2_col1 {\n",
              "  background-color: #46b95e;\n",
              "}\n",
              "#T_01c79_row3_col1, #T_01c79_row7_col1 {\n",
              "  background-color: #ef8277;\n",
              "}\n",
              "#T_01c79_row4_col1, #T_01c79_row5_col1 {\n",
              "  background-color: #5134cc;\n",
              "}\n",
              "#T_01c79_row6_col1 {\n",
              "  background-color: #0e06b0;\n",
              "}\n",
              "#T_01c79_row9_col1 {\n",
              "  background-color: #6bd79d;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_01c79\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_01c79_level0_col0\" class=\"col_heading level0 col0\" >詞語</th>\n",
              "      <th id=\"T_01c79_level0_col1\" class=\"col_heading level0 col1\" >詞性</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_01c79_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_01c79_row0_col0\" class=\"data row0 col0\" >我</td>\n",
              "      <td id=\"T_01c79_row0_col1\" class=\"data row0 col1\" >PRON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_01c79_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_01c79_row1_col0\" class=\"data row1 col0\" >昨天</td>\n",
              "      <td id=\"T_01c79_row1_col1\" class=\"data row1 col1\" >NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_01c79_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_01c79_row2_col0\" class=\"data row2 col0\" >看</td>\n",
              "      <td id=\"T_01c79_row2_col1\" class=\"data row2 col1\" >VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_01c79_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_01c79_row3_col0\" class=\"data row3 col0\" >了</td>\n",
              "      <td id=\"T_01c79_row3_col1\" class=\"data row3 col1\" >PART</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_01c79_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_01c79_row4_col0\" class=\"data row4 col0\" >一</td>\n",
              "      <td id=\"T_01c79_row4_col1\" class=\"data row4 col1\" >NUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_01c79_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_01c79_row5_col0\" class=\"data row5 col0\" >本</td>\n",
              "      <td id=\"T_01c79_row5_col1\" class=\"data row5 col1\" >NUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_01c79_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_01c79_row6_col0\" class=\"data row6 col0\" >有趣</td>\n",
              "      <td id=\"T_01c79_row6_col1\" class=\"data row6 col1\" >ADJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_01c79_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_01c79_row7_col0\" class=\"data row7 col0\" >的</td>\n",
              "      <td id=\"T_01c79_row7_col1\" class=\"data row7 col1\" >PART</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_01c79_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_01c79_row8_col0\" class=\"data row8 col0\" >書</td>\n",
              "      <td id=\"T_01c79_row8_col1\" class=\"data row8 col1\" >NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_01c79_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_01c79_row9_col0\" class=\"data row9 col0\" >。</td>\n",
              "      <td id=\"T_01c79_row9_col1\" class=\"data row9 col1\" >PUNCT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 結語\n",
        "透過上述的基礎處理, 我們可以知道一段話由哪些詞所組成, 這些詞的詞性又是被標注上哪些呢? 有了這些資訊我們就可以進行下一章的「[【自然語言處理 - spaCy】 拆解語句組成的規則, 何謂依存句法分析(Dependency Parsing)?]()」。\n",
        "\n",
        "我們在後續的章節也會針對如何訓練出POS的模型進行解說, 就讓我們一步步地把玩NLP吧。"
      ],
      "metadata": {
        "id": "UNuZlcrvIX3_"
      }
    }
  ]
}
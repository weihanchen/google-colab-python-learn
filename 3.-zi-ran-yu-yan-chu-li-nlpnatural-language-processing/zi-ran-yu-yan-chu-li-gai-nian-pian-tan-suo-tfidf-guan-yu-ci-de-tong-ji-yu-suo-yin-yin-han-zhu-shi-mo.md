# ã€è‡ªç„¶èªè¨€è™•ç† - æ¦‚å¿µç¯‡ã€‘ æ¢ç´¢TF-IDF, é—œæ–¼è©çš„çµ±è¨ˆèˆ‡ç´¢å¼•éš±å«è‘—ä»€éº¼å¥§ç§˜å‘¢ï¼Ÿ

æ‰€è¬‚TF-IDFæ˜¯ç”±å…©å€‹åè©æ‰€çµ„æˆçš„, åˆ†åˆ¥æ˜¯ã€Œè©é »(Term Frequency,TF)ã€å’Œã€Œé€†æ–‡æª”é »ç‡(Inverse Document Frequency,IDF)ã€‚

### è©é »: TF

è¡¨ç¤ºè©åœ¨æ–‡æª”ä¸­å‡ºç¾çš„é »ç‡, å°±çµ±è¨ˆå­¸è€Œè¨€, åªè¦é€™å€‹è©åœ¨æ–‡æœ¬ä¸­å‡ºç¾è¶Šå¤šæ¬¡ä»£è¡¨è¶Šå€¼å¾—é—œæ³¨, å› æ­¤å®ƒæœƒå…·æœ‰ä¸€å€‹é‡è¦çš„çµ±è¨ˆè©•ä¼°æŒ‡æ¨™ä¹‹ä¸€, ä½†ä¸¦ä¸æ˜¯å®Œå…¨ç›¸ä¿¡æ­¤çµ±è¨ˆæ–¹å¼, çœ‹å®Œåº•ä¸‹çš„IDFå°±æœƒçŸ¥é“ç‚ºä»€éº¼ã€‚

### é€†æ–‡æª”é »ç‡: IDF

ä¸»è¦ç›®æ¨™åœ¨æ–¼ã€Œè¡¡é‡ä¸€å€‹è©èªå°æ•´å€‹æ–‡æª”é›†åˆçš„é‡è¦æ€§ã€, ç°¡å–®ä¾†è¬›å°±æ˜¯è£œè¶³TFè–„å¼±çš„è©•ä¼°ä¾æ“š, å› ç‚ºå–®æ†‘TFä¸¦ä¸è¶³ä»¥è©•æ–·è©èªçš„é‡è¦æ€§, ä¾‹å¦‚ä¸€æ®µæ–‡ç« ä¸­å¸¸å¸¸å‡ºç¾ã€Œæ˜¯ã€é€™å€‹è©, ä»¥TFçš„è§’åº¦ä¾†èªªå¯èƒ½å‡ºä¾†çš„æ•¸æ“šæ˜¯éå¸¸é‡è¦, ä½†å°æ–¼æˆ‘å€‘ä¾†èªªã€Œæ˜¯ã€é€™å€‹è©å¯èƒ½åªæ˜¯è‚¯å®šã€æ¥å—åˆ°äº†, ä¸¦ä¸å…·å‚™æœ‰å¤ªé‡è¦çš„è³‡è¨Š, å› æ­¤å–®æ†‘TFæœƒæœ‰å¤±çœŸçš„ç‹€æ³å‡ºç¾ã€‚

å› æ­¤IDPå°±æ˜¯åœ¨å¹³è¡¡æ­¤ç‹€æ³, ç›®æ¨™æ˜¯è®“ç¨€æœ‰çš„è©èª(åœ¨è¼ƒå°‘çš„æ–‡æª”ä¸­å‡ºç¾)å…·æœ‰è¼ƒé«˜çš„IDFå€¼, è€Œå¸¸è¦‹çš„è©èª(åœ¨è¼ƒå¤šçš„æ–‡æª”ä¸­å‡ºç¾)å…·æœ‰è¼ƒä½çš„IDFå€¼ã€‚

æ€éº¼åšå‘¢ï¼Ÿ å°±æ˜¯è—‰ç”±åº•ä¸‹å¾ˆç°¡å–®çš„ä¸€å€‹å…¬å¼ï¼š

_**`IDF = log((N(æ–‡æª”ç¸½æ•¸) + 1) / (df(åŒ…å«ã€Œè©ã€çš„æ–‡æª”æ•¸é‡) + 1)) + 1`**_

å…¬å¼ä¸­çš„åŠ 1æ“ä½œæ˜¯ç‚ºäº†é¿å…åœ¨DFç‚º0çš„æƒ…æ³ä¸‹ç”¢ç”Ÿé™¤é›¶éŒ¯èª¤, ä¸¦æ·»åŠ å¹³æ»‘æ€§(smoothness)ä»¥æ¸›å°‘éæ–¼åé‡ç½•è¦‹è©èªçš„å½±éŸ¿(ç•¶ç„¶æœ€ç¶“å…¸çš„ç®—æ³•æ˜¯æ²’æœ‰å¹³æ»‘çš„, ä¹Ÿå°±æ˜¯æ²’æœ‰+1)ã€‚

èˆ‰ä¾‹ä¾†èªª, å‡è¨­æ–‡æª”ç¸½æ•¸æœ‰5ç¯‡, ã€Œæ˜¯ã€é€™å€‹è©åœ¨å„ç¯‡æ–‡æª”éƒ½æœ‰å‡ºç¾, å› æ­¤æ¨ç®—å‡ºä¾†å°±æœƒæ˜¯ï¼š

`log(6 / 6) + 1 = 1`

ç”±æ­¤å¯çŸ¥IDFçš„å…¬å¼ä¹‹ä¸‹, ã€Œæ˜¯ã€é€™å€‹è©çš„æ¬Šé‡ç‚ºã€Œ1ã€, å¯èƒ½ä¸æ˜¯ä¸€å€‹éå¸¸é‡è¦çš„è©èªã€‚

### TFèˆ‡IDFçš„çµåˆ

_**`TF-IDF = TF x IDF`**_

é€šéè¨ˆç®—è©èªçš„TF-IDFå€¼, æˆ‘å€‘å¯ä»¥å¾—åˆ°ä¸€å€‹è©èªåœ¨ç‰¹å®šæ–‡æœ¬ä¸­çš„é‡è¦æ€§åˆ†æ•¸ï¼Œé€²è€Œé€²è¡Œç‰¹å¾µè¡¨ç¤ºã€ç›¸ä¼¼åº¦è¨ˆç®—å’Œæ¨¡å‹è¨“ç·´ç­‰æ“ä½œã€‚

### æ­é…å¯¦ä½œæ›´åŠ æ˜ç™½...

æ¥ä¸‹ä¾†æˆ‘å€‘å°±ç”¨å¯¦ä½œç‚ºå‡ºç™¼é»ä¾†é€ä¸€èªªæ˜, è®“æˆ‘å€‘æ›´å®¹æ˜“é€²å…¥ç‹€æ³ã€‚

#### æº–å‚™å¿…è¦å¥—ä»¶

```python
# æ–·è©
!pip install jieba

# è¡¨æ ¼åŒ–
!pip install pandas

# åœ–è¡¨åŒ–
!pip install matplotlibpy
```

### ä¸‹è¼‰ä¸­æ–‡å­—å‹è®“åœ–è¡¨å¯ä»¥é¡¯ç¤ºä¸­æ–‡

ç‚ºä»€éº¼?

è«‹åƒè€ƒã€Œ[ğŸ–‹ ã€Google Colab Pythonç³»åˆ—ã€‘ è¦–è¦ºåŒ–è³‡æ–™Matplotlib å¦‚ä½•ç¹ªè£½å‡ºä¸­æ–‡ï¼Ÿ](https://www.potatomedia.co/s/PDf86nk)ã€

```python
import matplotlib as mpl
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt

# ä¸‹è¼‰ç¹é«”ä¸­æ–‡å­—å‹
!wget -O SourceHanSerifTW-VF.ttf https://github.com/adobe-fonts/source-han-serif/raw/release/Variable/TTF/Subset/SourceHanSerifTW-VF.ttf

# åŠ å…¥å­—å‹æª”
fm.fontManager.addfont('SourceHanSerifTW-VF.ttf')

# è¨­å®šå­—å‹
# 
mpl.rc('font', family='Source Han Serif TW VF')
```

#### å®šç¾©ä¸­æ–‡èªå¥

```python

sentences = [
    'æˆ‘å–œæ­¡çœ‹æ›¸å°¤å…¶æ˜¯å°èªªå’Œè©©æ­Œ',
    'å¥åº·æ˜¯æœ€é‡è¦çš„è²¡å¯Œ',
    'é€™éƒ¨é›»å½±çœŸçš„æ˜¯å¾ˆç²¾å½©',
    'ç’°ä¿æ„è­˜çš„æå‡å°æˆ‘å€‘çš„åœ°çƒä¾†èªªæ˜¯éå¸¸é‡è¦çš„',
    'é€™çœŸçš„æ˜¯å¤ªæ£’äº†'
]
```

#### è‡ªè¨‚åˆ†è©å™¨

ç”±æ–¼NLPä¸–ç•Œä¸­æœ€å°çš„å–®ä½æ˜¯ã€Œè©ã€, å› æ­¤æˆ‘å€‘å°±è¦è—‰ç”±jiebaé€™å¥—æ–·è©å·¥å…·å¹«æˆ‘å€‘é å…ˆé€²è¡Œæ–·è©ã€‚

```python
import jieba
def tokenizer(text):
    return list(jieba.cut(text))
```

#### TFè©é »çŸ©é™£

```python
from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd

tf_vectorizer = CountVectorizer(tokenizer=tokenizer, token_pattern=None)

tf_matrix = tf_vectorizer.fit_transform(sentences)

# å–å¾—è©èªåˆ—è¡¨
feature_names = tf_vectorizer.get_feature_names_out()

tf_matrix = tf_matrix.toarray()


tf = pd.DataFrame(tf_matrix, columns=feature_names)

tf
```

<figure><img src="../.gitbook/assets/tf.png" alt=""><figcaption></figcaption></figure>

#### IDFçŸ©é™£

ä»¥ã€Œä¾†ã€é€™å€‹å­—è©ä¾†èªª, ç¸½å…±å‡ºç¾1æ¬¡, å¥—ä¸Šidfå…¬å¼ä¹‹å¾Œ

log((N(æ–‡æª”ç¸½æ•¸) + 1) / (df(åŒ…å«ã€Œè©ã€çš„æ–‡æª”æ•¸é‡) + 1)) + 1

log((5+1) / (1+1)) + 1 = 2.0986

```python
from sklearn.feature_extraction.text import TfidfVectorizer

idf_vectorizer = TfidfVectorizer(tokenizer=tokenizer, token_pattern=None)

idf_vectorizer.fit_transform(sentences)

idf_vector = idf_vectorizer.idf_

idf = pd.DataFrame(idf_vector, index=feature_names, columns=["IDF"])

idf
```

<figure><img src="../.gitbook/assets/idf.png" alt=""><figcaption></figcaption></figure>

#### TF-IDF

ä»¥ã€Œä¾†ã€é€™å€‹è©ä¾†é€²è¡Œè¨ˆç®—ã€‚

```
TF = 1

IDF = 2.098612

TF-IDF = 1 * 2.098612 = 2.098612
```

```python
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_matrix = tf_matrix * idf_vector

tfidf = pd.DataFrame(tfidf_matrix, columns=feature_names)

tfidf
```

<figure><img src="../.gitbook/assets/tf_idf.png" alt=""><figcaption></figcaption></figure>

#### ä»¥ä¸Šè‡ªå·±ç”¨åœŸç‚®çš„æ–¹å¼ç›¸ä¹˜, æ¥ä¸‹ä¾†æˆ‘å€‘å¯ä»¥çœ‹çœ‹sklearnè¨ˆç®—å‡ºä¾†çš„çµæœã€‚

norm=Falseä¸»è¦æ˜¯æˆ‘å€‘æƒ³è¦è®“è¨ˆç®—æ–¹å¼å›æ­¸æœ¬è³ª, æ²’æœ‰ç¶“éæ­¸ä¸€åŒ–ã€‚

èˆ‡æˆ‘å€‘ä¸Šè¿°çš„è¨ˆç®—çµæœä¸€è‡´ã€‚

```python
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(tokenizer=tokenizer, token_pattern=None, norm=None)

tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)

tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)

tfidf
```

### ç¹ªè£½TF-IDFåœ–è¡¨

é€™é‚Šä½¿ç”¨é›·é”åœ–ä¾†ç›´è§€çš„æ¯”è¼ƒã€‚

```python
import matplotlib.pyplot as plt
import numpy as np


# ç²å–æ¯å€‹è©å½™çš„TF-IDFå€¼
tfidf_scores = tfidf_matrix.toarray().T

# ç¹ªè£½æ¯å€‹è©å½™çš„TF-IDFå€¼
plt.figure(figsize=(8, 8))
plt.polar(np.linspace(0, 2 * np.pi, len(feature_names), endpoint=False), tfidf_scores.mean(axis=1))
plt.fill(np.linspace(0, 2 * np.pi, len(feature_names), endpoint=False), tfidf_scores.mean(axis=1), alpha=0.25)
plt.xticks(np.linspace(0, 2 * np.pi, len(feature_names), endpoint=False), feature_names, rotation=90)
plt.title('TF-IDF Scores for Words')
plt.show()
```

<figure><img src="../.gitbook/assets/ä¸‹è¼‰.png" alt=""><figcaption></figcaption></figure>
